#!/usr/bin/env python3
"""
Weekly Analysis and Export for EmoJournal Bot
Generates insights and CSV exports based on user data
FIXED: Corrected emotion categorization logic
"""

import logging
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional
import json
import csv
import io
from collections import Counter, defaultdict

from .i18n import Texts, format_emotion_list, get_time_period_text, generate_insight

logger = logging.getLogger(__name__)

class WeeklyAnalyzer:
    """Analyzes user emotion data and generates insights with correct categorization"""
    
    # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ß–µ—Ç–∫–∏–µ —Å–ø–∏—Å–∫–∏ —ç–º–æ—Ü–∏–π –¥–ª—è –∫–∞–∂–¥–æ–π –≥—Ä—É–ø–ø—ã (–≤ –Ω–∏–∂–Ω–µ–º —Ä–µ–≥–∏—Å—Ç—Ä–µ –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è)
    EMOTION_GROUPS = {
        'growth': {
            'name': 'üå± –≠–º–æ—Ü–∏–∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –∏ —Ä–æ—Å—Ç–∞',
            'emotions': {
                # –†–∞–¥–æ—Å—Ç—å/–£–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–µ–Ω–∏–µ
                '—Ä–∞–¥–æ—Å—Ç—å', '—Å—á–∞—Å—Ç—å–µ', '–≤–æ—Å—Ç–æ—Ä–≥', '—É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–µ–Ω–∏–µ', '–±–ª–∞–≥–æ–¥–∞—Ä–Ω–æ—Å—Ç—å', 
                '–≤–¥–æ—Ö–Ω–æ–≤–µ–Ω–∏–µ', '—ç–π—Ñ–æ—Ä–∏—è', '–±–ª–∞–∂–µ–Ω—Å—Ç–≤–æ', '–ª–∏–∫–æ–≤–∞–Ω–∏–µ', '–≤–æ—Å—Ö–∏—â–µ–Ω–∏–µ', '—É–º–∏–ª–µ–Ω–∏–µ',
                # –ò–Ω—Ç–µ—Ä–µ—Å/–õ—é–±–æ–ø—ã—Ç—Å—Ç–≤–æ
                '–∏–Ω—Ç–µ—Ä–µ—Å', '–ª—é–±–æ–ø—ã—Ç—Å—Ç–≤–æ', '—É–≤–ª–µ—á—ë–Ω–Ω–æ—Å—Ç—å', '–ø—Ä–µ–¥–≤–∫—É—à–µ–Ω–∏–µ', '–∞–∑–∞—Ä—Ç', 
                '—ç–Ω—Ç—É–∑–∏–∞–∑–º', '–≤–æ–æ–¥—É—à–µ–≤–ª–µ–Ω–∏–µ',
                # –°–ø–æ–∫–æ–π—Å—Ç–≤–∏–µ/–£–º–∏—Ä–æ—Ç–≤–æ—Ä–µ–Ω–∏–µ
                '—Å–ø–æ–∫–æ–π—Å—Ç–≤–∏–µ', '—É–º–∏—Ä–æ—Ç–≤–æ—Ä–µ–Ω–∏–µ', '—Ä–∞—Å—Å–ª–∞–±–ª–µ–Ω–Ω–æ—Å—Ç—å', '–±–µ–∑–º—è—Ç–µ–∂–Ω–æ—Å—Ç—å', 
                '–ø—Ä–∏–Ω—è—Ç–∏–µ', '–≥–∞—Ä–º–æ–Ω–∏—è', '–±–∞–ª–∞–Ω—Å', '—Ü–µ–Ω—Ç—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ—Å—Ç—å', '–ø–æ–∫–æ–π'
            }
        },
        'tension': {
            'name': 'üå™ –≠–º–æ—Ü–∏–∏ –Ω–∞–ø—Ä—è–∂–µ–Ω–∏—è –∏ —Å–∏–≥–Ω–∞–ª–∞',
            'emotions': {
                # –¢—Ä–µ–≤–æ–≥–∞/–ë–µ—Å–ø–æ–∫–æ–π—Å—Ç–≤–æ
                '—Ç—Ä–µ–≤–æ–≥–∞', '–±–µ—Å–ø–æ–∫–æ–π—Å—Ç–≤–æ', '–Ω–µ—Ä–≤–æ–∑–Ω–æ—Å—Ç—å', '–≤–æ–ª–Ω–µ–Ω–∏–µ', '–Ω–∞–ø—Ä—è–∂–µ–Ω–∏–µ', 
                '—Å—Ç—Ä–∞—Ö', '–ø–∞–Ω–∏–∫–∞', '–æ–ø–∞—Å–µ–Ω–∏—è', '–≤—Å—Ç—Ä–µ–≤–æ–∂–µ–Ω–Ω–æ—Å—Ç—å',
                # –ì—Ä—É—Å—Ç—å/–ü–µ—á–∞–ª—å
                '–≥—Ä—É—Å—Ç—å', '–ø–µ—á–∞–ª—å', '—Ç–æ—Å–∫–∞', '—É–Ω—ã–Ω–∏–µ', '—Ä–∞–∑–æ—á–∞—Ä–æ–≤–∞–Ω–∏–µ', '—Å–æ–∂–∞–ª–µ–Ω–∏–µ', 
                '–º–µ–ª–∞–Ω—Ö–æ–ª–∏—è', '–≥–æ—Ä–µ', '—Å–∫–æ—Ä–±—å', '–ø–æ–¥–∞–≤–ª–µ–Ω–Ω–æ—Å—Ç—å',
                # –ó–ª–æ—Å—Ç—å/–†–∞–∑–¥—Ä–∞–∂–µ–Ω–∏–µ
                '–∑–ª–æ—Å—Ç—å', '—Ä–∞–∑–¥—Ä–∞–∂–µ–Ω–∏–µ', '–≥–Ω–µ–≤', '–≤–æ–∑–º—É—â–µ–Ω–∏–µ', '–æ–±–∏–¥–∞', '—Ñ—Ä—É—Å—Ç—Ä–∞—Ü–∏—è', 
                '–¥–æ—Å–∞–¥–∞', '–Ω–µ–≥–æ–¥–æ–≤–∞–Ω–∏–µ', '—è—Ä–æ—Å—Ç—å', '–Ω–µ–¥–æ–≤–æ–ª—å—Å—Ç–≤–æ',
                # –°—Ç—ã–¥/–í–∏–Ω–∞
                '—Å—Ç—ã–¥', '–≤–∏–Ω–∞', '—Å–º—É—â–µ–Ω–∏–µ', '–Ω–µ–ª–æ–≤–∫–æ—Å—Ç—å', '—Å–∞–º–æ–∫—Ä–∏—Ç–∏–∫–∞', '—Ä–∞—Å–∫–∞—è–Ω–∏–µ', 
                '—É–≥—Ä—ã–∑–µ–Ω–∏—è —Å–æ–≤–µ—Å—Ç–∏',
                # –£—Å—Ç–∞–ª–æ—Å—Ç—å/–ò—Å—Ç–æ—â–µ–Ω–∏–µ
                '—É—Å—Ç–∞–ª–æ—Å—Ç—å', '–∏—Å—Ç–æ—â–µ–Ω–∏–µ', '–≤—è–ª–æ—Å—Ç—å', '–∞–ø–∞—Ç–∏—è', '–±–µ–∑—Ä–∞–∑–ª–∏—á–∏–µ', 
                '–≤—ã–≥–æ—Ä–∞–Ω–∏–µ', '–∏–∑–Ω–µ–º–æ–∂–µ–Ω–∏–µ', '–æ–ø—É—Å—Ç–æ—à—ë–Ω–Ω–æ—Å—Ç—å'
            }
        },
        'neutral': {
            'name': '‚öñ –ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã–µ/–ø—Ä–æ—á–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è',
            'emotions': {
                # –≠–Ω–µ—Ä–≥–∏—è/–ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
                '–æ–∂–∏–≤–ª–µ–Ω–∏–µ', '—ç–Ω–µ—Ä–≥–∏—è', '–±–æ–¥—Ä–æ—Å—Ç—å', '–∂–∏–≤–æ—Å—Ç—å', '–∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å', 
                '–ø–æ–¥—ä—ë–º', '–¥—Ä–∞–π–≤', '–¥–∏–Ω–∞–º–∏–∑–º'
            }
        }
    }
    
    def __init__(self, db):
        self.db = db
        self.texts = Texts()
    
    async def generate_summary(self, user_id: int, days: int = 7) -> str:
        """Generate enhanced summary with emotion grouping"""
        try:
            entries = self.db.get_user_entries(user_id, days)
            
            if len(entries) == 0:
                return self.texts.NO_DATA_MESSAGE
            
            if len(entries) == 1:
                # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è –æ–¥–Ω–æ–π –∑–∞–ø–∏—Å–∏
                entry = entries[0]
                emotions = self._parse_emotions(entry.emotions) if entry.emotions else ['–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ']
                return f"""üìä <b>–¢–≤–æ—è –ø–µ—Ä–≤–∞—è –∑–∞–ø–∏—Å—å!</b>

<b>üé≠ –≠–º–æ—Ü–∏—è:</b> {', '.join(emotions)}

<b>üîç –ü—Ä–∏—á–∏–Ω–∞:</b> {entry.cause if entry.cause else '–Ω–µ —É–∫–∞–∑–∞–Ω–∞'}

<b>‚è∞ –í—Ä–µ–º—è:</b> {entry.ts_local.strftime('%H:%M')} ({get_time_period_text(entry.ts_local.hour)})

<b>üìà –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π:</b> 1

üí° <b>–û—Ç–ª–∏—á–Ω–æ!</b> –¢—ã —Å–¥–µ–ª–∞–ª(–∞) –ø–µ—Ä–≤—ã–π —à–∞–≥ –∫ –æ—Å–æ–∑–Ω–∞–Ω–Ω–æ—Å—Ç–∏. –ü—Ä–æ–¥–æ–ª–∂–∞–π –∑–∞–ø–∏—Å—ã–≤–∞—Ç—å —ç–º–æ—Ü–∏–∏, –∏ –≤—Å–∫–æ—Ä–µ —è —Å–º–æ–≥—É –ø–æ–∫–∞–∑–∞—Ç—å –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–µ –∑–∞–∫–æ–Ω–æ–º–µ—Ä–Ω–æ—Å—Ç–∏!

<i>–ò—Å–ø–æ–ª—å–∑—É–π /note –¥–ª—è –Ω–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π.</i>"""
            
            # –ê–Ω–∞–ª–∏–∑ –¥–ª—è 2+ –∑–∞–ø–∏—Å–µ–π
            emotion_analysis = self._analyze_emotions_by_groups(entries)
            trigger_analysis = self._analyze_triggers_by_groups(entries)
            
            time_dist = self._analyze_time_distribution(entries)
            peak_hour = max(time_dist.items(), key=lambda x: x[1])[0] if time_dist else 12
            peak_period = get_time_period_text(peak_hour)
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–Ω—Å–∞–π—Ç—ã
            insights = self._generate_enhanced_insights(entries, emotion_analysis, trigger_analysis)
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –Ω–æ–≤—É—é —Å–≤–æ–¥–∫—É
            summary = self._format_enhanced_summary(
                emotion_analysis, 
                trigger_analysis, 
                peak_hour, 
                peak_period, 
                len(entries), 
                insights
            )
            
            return summary
            
        except Exception as e:
            logger.error(f"Failed to generate summary for user {user_id}: {e}")
            return "–ù–µ —É–¥–∞–ª–æ—Å—å —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å —Å–≤–æ–¥–∫—É. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."
    
    def _get_emotion_group(self, emotion: str) -> str:
        """–ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –≥—Ä—É–ø–ø—É —ç–º–æ—Ü–∏–∏ –ø–æ —á–µ—Ç–∫–∏–º —Å–ø–∏—Å–∫–∞–º"""
        if not emotion:
            return 'neutral'
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —ç–º–æ—Ü–∏—é
        emotion_normalized = self._normalize_emotion(emotion)
        if not emotion_normalized:
            return 'neutral'
        
        emotion_clean = emotion_normalized.lower().strip()
        
        # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤ –∫–∞–∂–¥–æ–π –≥—Ä—É–ø–ø–µ, –∏—Å–ø–æ–ª—å–∑—É—è set –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
        for group_key, group_data in self.EMOTION_GROUPS.items():
            if emotion_clean in group_data['emotions']:
                return group_key
        
        # –ï—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ - –Ω–µ–π—Ç—Ä–∞–ª—å–Ω–∞—è
        return 'neutral'
    
    def _analyze_emotions_by_groups(self, entries) -> Dict:
        """–ê–Ω–∞–ª–∏–∑ —ç–º–æ—Ü–∏–π –ø–æ –Ω–æ–≤—ã–º –≥—Ä—É–ø–ø–∞–º"""
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º —ç–º–æ—Ü–∏–∏
        grouped_emotions = {
            'growth': defaultdict(int),
            'tension': defaultdict(int), 
            'neutral': defaultdict(int)
        }
        
        for entry in entries:
            if entry.emotions:
                emotions = self._parse_emotions(entry.emotions)
                for emotion in emotions:
                    normalized = self._normalize_emotion(emotion)
                    if normalized:
                        group = self._get_emotion_group(normalized)
                        grouped_emotions[group][normalized] += 1
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        result = {}
        for group_key, group_info in self.EMOTION_GROUPS.items():
            emotions_in_group = dict(grouped_emotions[group_key])
            total_count = sum(emotions_in_group.values())
            top_emotions = sorted(emotions_in_group.items(), key=lambda x: x[1], reverse=True)[:5]
            
            result[group_key] = {
                'name': group_info['name'],
                'total_count': total_count,
                'emotions': emotions_in_group,
                'top_emotions': top_emotions
            }
        
        return result
    
    def _analyze_triggers_by_groups(self, entries) -> Dict:
        """–ê–Ω–∞–ª–∏–∑ —Ç—Ä–∏–≥–≥–µ—Ä–æ–≤ –ø–æ –≥—Ä—É–ø–ø–∞–º —ç–º–æ—Ü–∏–π"""
        # –°–æ–±–∏—Ä–∞–µ–º —Ç—Ä–∏–≥–≥–µ—Ä—ã –¥–ª—è –∫–∞–∂–¥–æ–π –≥—Ä—É–ø–ø—ã —ç–º–æ—Ü–∏–π
        grouped_triggers = {
            'growth': [],
            'tension': [],
            'neutral': []
        }
        
        for entry in entries:
            if entry.cause and entry.emotions:
                emotions = self._parse_emotions(entry.emotions)
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫ –∫–∞–∫–æ–π –≥—Ä—É–ø–ø–µ –æ—Ç–Ω–æ—Å–∏—Ç—Å—è —ç—Ç–∞ –∑–∞–ø–∏—Å—å
                emotion_groups = []
                for emotion in emotions:
                    normalized = self._normalize_emotion(emotion)
                    if normalized:
                        group = self._get_emotion_group(normalized)
                        emotion_groups.append(group)
                
                # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: tension > growth > neutral
                if 'tension' in emotion_groups:
                    grouped_triggers['tension'].append(entry.cause.strip())
                elif 'growth' in emotion_groups:
                    grouped_triggers['growth'].append(entry.cause.strip())
                else:
                    grouped_triggers['neutral'].append(entry.cause.strip())
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        result = {}
        trigger_names = {
            'growth': 'üå± –ß—Ç–æ —Å–ø—Ä–æ–≤–æ—Ü–∏—Ä–æ–≤–∞–ª–æ —ç–º–æ—Ü–∏–∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –∏ —Ä–æ—Å—Ç–∞',
            'tension': 'üå™ –¢—Ä–∏–≥–≥–µ—Ä—ã —ç–º–æ—Ü–∏–π –Ω–∞–ø—Ä—è–∂–µ–Ω–∏—è –∏ —Å–∏–≥–Ω–∞–ª–∞',
            'neutral': '‚öñ –¢—Ä–∏–≥–≥–µ—Ä—ã –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã—Ö —ç–º–æ—Ü–∏–π'
        }
        
        for group_key in ['growth', 'tension', 'neutral']:
            triggers = grouped_triggers[group_key]
            result[group_key] = {
                'name': trigger_names[group_key],
                'triggers': triggers,
                'count': len(triggers)
            }
        
        return result
    
    def _format_enhanced_summary(self, emotion_analysis, trigger_analysis, peak_hour, peak_period, total_entries, insights):
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–æ–≤–æ–π —Å–≤–æ–¥–∫–∏"""
        
        summary_parts = [
            "üìä <b>–¢–≤–æ—è –Ω–µ–¥–µ–ª—è –≤ —ç–º–æ—Ü–∏—è—Ö</b>\n",
            "<b>üé≠ –≠–º–æ—Ü–∏–∏ –ø–æ –≥—Ä—É–ø–ø–∞–º:</b>\n"
        ]
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –±–ª–æ–∫–∏ —ç–º–æ—Ü–∏–π (–ø–æ–∫–∞–∑—ã–≤–∞–µ–º –≤—Å–µ –≥—Ä—É–ø–ø—ã, –¥–∞–∂–µ —Å 0)
        for group_key in ['growth', 'tension', 'neutral']:
            group_data = emotion_analysis[group_key]
            
            if group_data['total_count'] > 0:
                top_emotions_str = ', '.join([f"{emotion} ({count})" for emotion, count in group_data['top_emotions']])
                summary_parts.append(f"<b>{group_data['name']}:</b> {group_data['total_count']} —Ä–∞–∑")
                summary_parts.append(f"{top_emotions_str}\n")
            else:
                summary_parts.append(f"<b>{group_data['name']}:</b> 0 —Ä–∞–∑\n")
        
        summary_parts.append("<b>üîç –ß—Ç–æ –≤–ª–∏—è–ª–æ –Ω–∞ —ç–º–æ—Ü–∏–∏:</b>\n")
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –±–ª–æ–∫–∏ —Ç—Ä–∏–≥–≥–µ—Ä–æ–≤ (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å —Ç—Ä–∏–≥–≥–µ—Ä—ã)
        for group_key in ['growth', 'tension', 'neutral']:
            group_data = trigger_analysis[group_key]
            if group_data['count'] > 0:
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –¥–æ 5 —Ç—Ä–∏–≥–≥–µ—Ä–æ–≤
                sample_triggers = group_data['triggers'][:5]
                triggers_formatted = []
                for trigger in sample_triggers:
                    triggers_formatted.append(f"‚Ä¢ {trigger}")
                
                triggers_str = '\n'.join(triggers_formatted)
                if len(group_data['triggers']) > 5:
                    triggers_str += f"\n<i>(–∏ –µ—â—ë {len(group_data['triggers']) - 5})</i>"
                
                summary_parts.append(f"<b>{group_data['name']}:</b>")
                summary_parts.append(f"{triggers_str}\n")
        
        summary_parts.extend([
            f"<b>‚è∞ –ü–∏–∫ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏:</b> {peak_hour:02d}:00 ({peak_period})",
            f"<b>üìà –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π:</b> {total_entries}",
            ""
        ])
        
        if insights:
            summary_parts.append(insights)
            summary_parts.append("")
        
        summary_parts.append("<i>–•–æ—á–µ—à—å –ø–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏? –ò—Å–ø–æ–ª—å–∑—É–π /export –¥–ª—è CSV-—Ñ–∞–π–ª–∞.</i>")
        
        return "\n".join(summary_parts)
    
    def _generate_enhanced_insights(self, entries, emotion_analysis, trigger_analysis):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–Ω—Å–∞–π—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–æ–≤–æ–π –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏"""
        insights = []
        
        # –ê–Ω–∞–ª–∏–∑ –±–∞–ª–∞–Ω—Å–∞ —ç–º–æ—Ü–∏–π
        growth_count = emotion_analysis['growth']['total_count']
        tension_count = emotion_analysis['tension']['total_count']
        total_emotional = growth_count + tension_count
        
        if total_emotional > 0:
            growth_ratio = growth_count / total_emotional
            
            if growth_ratio >= 0.7:
                insights.append("‚ú® <b>–û—Ç–ª–∏—á–Ω—ã–π –±–∞–ª–∞–Ω—Å!</b> –ü—Ä–µ–æ–±–ª–∞–¥–∞—é—Ç —ç–º–æ—Ü–∏–∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –∏ —Ä–æ—Å—Ç–∞.")
            elif growth_ratio >= 0.4:
                insights.append("‚öñÔ∏è <b>–°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –Ω–µ–¥–µ–ª—è:</b> —ç–º–æ—Ü–∏–∏ —Ä–æ—Å—Ç–∞ –∏ –Ω–∞–ø—Ä—è–∂–µ–Ω–∏—è –≤ —Ä–∞–≤–Ω–æ–≤–µ—Å–∏–∏.")
            else:
                insights.append("ü§ó <b>–ù–µ–ø—Ä–æ—Å—Ç–∞—è –Ω–µ–¥–µ–ª—è:</b> –º–Ω–æ–≥–æ —ç–º–æ—Ü–∏–π –Ω–∞–ø—Ä—è–∂–µ–Ω–∏—è. –≠—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ - –æ–Ω–∏ —Ç–æ–∂–µ –≤–∞–∂–Ω—ã –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è —Å–µ–±—è.")
        
        # –ê–Ω–∞–ª–∏–∑ —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
        if len(entries) >= 5:
            # –ê–Ω–∞–ª–∏–∑ —Ç—Ä–∏–≥–≥–µ—Ä–æ–≤ —Ä–æ—Å—Ç–∞
            growth_triggers = trigger_analysis['growth']['triggers']
            if len(growth_triggers) >= 2:
                insights.append(f"üí° <b>–ß—Ç–æ —Ç–µ–±—è –≤–¥–æ—Ö–Ω–æ–≤–ª—è–µ—Ç:</b> –æ–±—Ä–∞—Ç–∏ –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ —Å–∏—Ç—É–∞—Ü–∏–∏, –∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–∏–Ω–æ—Å—è—Ç —ç–º–æ—Ü–∏–∏ —Ä–æ—Å—Ç–∞.")
            
            # –ê–Ω–∞–ª–∏–∑ —Ç—Ä–∏–≥–≥–µ—Ä–æ–≤ –Ω–∞–ø—Ä—è–∂–µ–Ω–∏—è
            tension_triggers = trigger_analysis['tension']['triggers']
            if len(tension_triggers) >= 2:
                insights.append(f"üõ°Ô∏è <b>–ó–æ–Ω—ã –≤–Ω–∏–º–∞–Ω–∏—è:</b> —Å—Ç–æ–∏—Ç –ø–æ–¥—É–º–∞—Ç—å –æ —Å—Ç—Ä–∞—Ç–µ–≥–∏—è—Ö —Ä–∞–±–æ—Ç—ã —Å –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–º–∏—Å—è —Å—Ç—Ä–µ—Å—Å–æ—Ä–∞–º–∏.")
        elif len(entries) >= 2:
            # –ü—Ä–æ—Å—Ç—ã–µ –∏–Ω—Å–∞–π—Ç—ã –¥–ª—è –Ω–µ–±–æ–ª—å—à–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∑–∞–ø–∏—Å–µ–π
            if growth_count > tension_count:
                insights.append("‚ú® –ó–¥–æ—Ä–æ–≤–æ, —á—Ç–æ –ø—Ä–µ–æ–±–ª–∞–¥–∞—é—Ç –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–µ —ç–º–æ—Ü–∏–∏!")
            elif tension_count > growth_count:
                insights.append("ü§ó –ó–∞–º–µ—á–∞—Ç—å —Å–ª–æ–∂–Ω—ã–µ —ç–º–æ—Ü–∏–∏ ‚Äî –≤–∞–∂–Ω—ã–π —à–∞–≥ –∫ –∏—Ö –ø–æ–Ω–∏–º–∞–Ω–∏—é.")
        
        return "\n\n".join(insights) if insights else ""
    
    def _parse_emotions(self, emotions_str: str) -> List[str]:
        """Parse emotions from JSON or plain text"""
        if not emotions_str:
            return []
        
        try:
            # Try parsing as JSON array
            emotions = json.loads(emotions_str)
            if isinstance(emotions, list):
                return [str(e).strip().lower() for e in emotions if e]
        except (json.JSONDecodeError, TypeError):
            pass
        
        # Fall back to plain text parsing
        return [emotions_str.strip().lower()] if emotions_str.strip() else []
    
    def _normalize_emotion(self, emotion: str) -> Optional[str]:
        """–ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: Normalize emotion to base form (enhanced Russian stemming)"""
        if not emotion or not isinstance(emotion, str):
            return None
            
        emotion = emotion.strip().lower()
        
        if len(emotion) < 2:
            return None
        
        # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –†–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–µ —Ä—É—Å—Å–∫–æ–µ –Ω–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —ç–º–æ—Ü–∏–π
        emotion_mapping = {
            # –†–∞–¥–æ—Å—Ç—å family
            '—Ä–∞–¥–æ—Å—Ç–Ω—ã–π': '—Ä–∞–¥–æ—Å—Ç—å', '—Ä–∞–¥–æ—Å—Ç–Ω–∞—è': '—Ä–∞–¥–æ—Å—Ç—å', '—Ä–∞–¥–æ—Å—Ç–Ω–æ–µ': '—Ä–∞–¥–æ—Å—Ç—å', '—Ä–∞–¥–æ—Å—Ç–Ω—ã–µ': '—Ä–∞–¥–æ—Å—Ç—å',
            '—Å—á–∞—Å—Ç–ª–∏–≤—ã–π': '—Å—á–∞—Å—Ç—å–µ', '—Å—á–∞—Å—Ç–ª–∏–≤–∞—è': '—Å—á–∞—Å—Ç—å–µ', '—Å—á–∞—Å—Ç–ª–∏–≤–æ–µ': '—Å—á–∞—Å—Ç—å–µ', '—Å—á–∞—Å—Ç–ª–∏–≤—ã–µ': '—Å—á–∞—Å—Ç—å–µ',
            '–¥–æ–≤–æ–ª—å–Ω—ã–π': '—É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–µ–Ω–∏–µ', '–¥–æ–≤–æ–ª—å–Ω–∞—è': '—É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–µ–Ω–∏–µ', '–¥–æ–≤–æ–ª—å–Ω–æ–µ': '—É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–µ–Ω–∏–µ',
            
            # –¢—Ä–µ–≤–æ–≥–∞ family  
            '—Ç—Ä–µ–≤–æ–∂–Ω—ã–π': '—Ç—Ä–µ–≤–æ–≥–∞', '—Ç—Ä–µ–≤–æ–∂–Ω–∞—è': '—Ç—Ä–µ–≤–æ–≥–∞', '—Ç—Ä–µ–≤–æ–∂–Ω–æ–µ': '—Ç—Ä–µ–≤–æ–≥–∞', '—Ç—Ä–µ–≤–æ–∂–Ω—ã–µ': '—Ç—Ä–µ–≤–æ–≥–∞',
            '–±–µ—Å–ø–æ–∫–æ–π–Ω—ã–π': '–±–µ—Å–ø–æ–∫–æ–π—Å—Ç–≤–æ', '–±–µ—Å–ø–æ–∫–æ–π–Ω–∞—è': '–±–µ—Å–ø–æ–∫–æ–π—Å—Ç–≤–æ', '–±–µ—Å–ø–æ–∫–æ–π–Ω–æ–µ': '–±–µ—Å–ø–æ–∫–æ–π—Å—Ç–≤–æ',
            '–Ω–µ—Ä–≤–Ω—ã–π': '–Ω–µ—Ä–≤–æ–∑–Ω–æ—Å—Ç—å', '–Ω–µ—Ä–≤–Ω–∞—è': '–Ω–µ—Ä–≤–æ–∑–Ω–æ—Å—Ç—å', '–Ω–µ—Ä–≤–Ω–æ–µ': '–Ω–µ—Ä–≤–æ–∑–Ω–æ—Å—Ç—å',
            '–≤–∑–≤–æ–ª–Ω–æ–≤–∞–Ω–Ω—ã–π': '–≤–æ–ª–Ω–µ–Ω–∏–µ', '–≤–∑–≤–æ–ª–Ω–æ–≤–∞–Ω–Ω–∞—è': '–≤–æ–ª–Ω–µ–Ω–∏–µ',
            
            # –ì—Ä—É—Å—Ç—å family
            '–≥—Ä—É—Å—Ç–Ω—ã–π': '–≥—Ä—É—Å—Ç—å', '–≥—Ä—É—Å—Ç–Ω–∞—è': '–≥—Ä—É—Å—Ç—å', '–≥—Ä—É—Å—Ç–Ω–æ–µ': '–≥—Ä—É—Å—Ç—å', '–≥—Ä—É—Å—Ç–Ω—ã–µ': '–≥—Ä—É—Å—Ç—å',
            '–ø–µ—á–∞–ª—å–Ω—ã–π': '–ø–µ—á–∞–ª—å', '–ø–µ—á–∞–ª—å–Ω–∞—è': '–ø–µ—á–∞–ª—å', '–ø–µ—á–∞–ª—å–Ω–æ–µ': '–ø–µ—á–∞–ª—å',
            '—Ä–∞—Å—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π': '—Ä–∞—Å—Å—Ç—Ä–æ–π—Å—Ç–≤–æ', '—Ä–∞—Å—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è': '—Ä–∞—Å—Å—Ç—Ä–æ–π—Å—Ç–≤–æ',
            
            # –ó–ª–æ—Å—Ç—å family
            '–∑–ª–æ–π': '–∑–ª–æ—Å—Ç—å', '–∑–ª–∞—è': '–∑–ª–æ—Å—Ç—å', '–∑–ª–æ–µ': '–∑–ª–æ—Å—Ç—å', '–∑–ª—ã–µ': '–∑–ª–æ—Å—Ç—å',
            '—Ä–∞–∑–¥—Ä–∞–∂—ë–Ω–Ω—ã–π': '—Ä–∞–∑–¥—Ä–∞–∂–µ–Ω–∏–µ', '—Ä–∞–∑–¥—Ä–∞–∂—ë–Ω–Ω–∞—è': '—Ä–∞–∑–¥—Ä–∞–∂–µ–Ω–∏–µ', '—Ä–∞–∑–¥—Ä–∞–∂–µ–Ω–Ω—ã–π': '—Ä–∞–∑–¥—Ä–∞–∂–µ–Ω–∏–µ',
            '—Å–µ—Ä–¥–∏—Ç—ã–π': '–∑–ª–æ—Å—Ç—å', '—Å–µ—Ä–¥–∏—Ç–∞—è': '–∑–ª–æ—Å—Ç—å',
            
            # –£—Å—Ç–∞–ª–æ—Å—Ç—å family
            '—É—Å—Ç–∞–ª—ã–π': '—É—Å—Ç–∞–ª–æ—Å—Ç—å', '—É—Å—Ç–∞–ª–∞—è': '—É—Å—Ç–∞–ª–æ—Å—Ç—å', '—É—Å—Ç–∞–ª–æ–µ': '—É—Å—Ç–∞–ª–æ—Å—Ç—å',
            '—É—Å—Ç–∞–≤—à–∏–π': '—É—Å—Ç–∞–ª–æ—Å—Ç—å', '—É—Å—Ç–∞–≤—à–∞—è': '—É—Å—Ç–∞–ª–æ—Å—Ç—å',
            '–∏–∑–º—É—á–µ–Ω–Ω—ã–π': '–∏—Å—Ç–æ—â–µ–Ω–∏–µ', '–∏–∑–º—É—á–µ–Ω–Ω–∞—è': '–∏—Å—Ç–æ—â–µ–Ω–∏–µ',
            
            # –°–ø–æ–∫–æ–π—Å—Ç–≤–∏–µ family
            '—Å–ø–æ–∫–æ–π–Ω—ã–π': '—Å–ø–æ–∫–æ–π—Å—Ç–≤–∏–µ', '—Å–ø–æ–∫–æ–π–Ω–∞—è': '—Å–ø–æ–∫–æ–π—Å—Ç–≤–∏–µ', '—Å–ø–æ–∫–æ–π–Ω–æ–µ': '—Å–ø–æ–∫–æ–π—Å—Ç–≤–∏–µ',
            '—Ä–∞—Å—Å–ª–∞–±–ª–µ–Ω–Ω—ã–π': '—Ä–∞—Å—Å–ª–∞–±–ª–µ–Ω–Ω–æ—Å—Ç—å', '—Ä–∞—Å—Å–ª–∞–±–ª–µ–Ω–Ω–∞—è': '—Ä–∞—Å—Å–ª–∞–±–ª–µ–Ω–Ω–æ—Å—Ç—å',
            
            # –ò–Ω—Ç–µ—Ä–µ—Å family
            '–∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ': '–∏–Ω—Ç–µ—Ä–µ—Å', '–∑–∞–∏–Ω—Ç–µ—Ä–µ—Å–æ–≤–∞–Ω–Ω—ã–π': '–∏–Ω—Ç–µ—Ä–µ—Å', '–∑–∞–∏–Ω—Ç–µ—Ä–µ—Å–æ–≤–∞–Ω–Ω–∞—è': '–∏–Ω—Ç–µ—Ä–µ—Å',
            '–ª—é–±–æ–ø—ã—Ç–Ω—ã–π': '–ª—é–±–æ–ø—ã—Ç—Å—Ç–≤–æ', '–ª—é–±–æ–ø—ã—Ç–Ω–∞—è': '–ª—é–±–æ–ø—ã—Ç—Å—Ç–≤–æ',
        }
        
        # Direct mapping
        if emotion in emotion_mapping:
            return emotion_mapping[emotion]
        
        # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –£–ª—É—á—à–µ–Ω–Ω–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ —Ä—É—Å—Å–∫–∏—Ö –æ–∫–æ–Ω—á–∞–Ω–∏–π
        endings_to_remove = [
            '—ã–π', '–∞—è', '–æ–µ', '—ã–µ', '–æ–π', '–µ–π', '–∏—Ö', '—ã–º', '—ã–º–∏', '—É—é', '—É—é', '–æ–≥–æ', '—É—é',
            '—ë–Ω', '–Ω–∞', '–Ω–æ', '–Ω—ã', '—ë–Ω–Ω—ã–π', '–µ–Ω–Ω—ã–π', '–Ω–Ω—ã–π'
        ]
        
        for ending in endings_to_remove:
            if emotion.endswith(ending) and len(emotion) > len(ending) + 2:
                base = emotion[:-len(ending)]
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –±–∞–∑–æ–≤–∞—è —Ñ–æ—Ä–º–∞ –≤ –Ω–∞—à–∏—Ö —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã—Ö –≥—Ä—É–ø–ø–∞—Ö
                for group_data in self.EMOTION_GROUPS.values():
                    if base in group_data['emotions']:
                        return base
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å, –µ—Å–ª–∏ –Ω–µ —Å–º–æ–≥–ª–∏ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å
        return emotion
    
    def _analyze_time_distribution(self, entries) -> Dict[int, int]:
        """Analyze distribution by hour of day"""
        hour_counts = Counter()
        
        for entry in entries:
            hour = entry.ts_local.hour
            hour_counts[hour] += 1
        
        return dict(hour_counts)
    
    async def export_csv(self, user_id: int) -> Optional[str]:
        """Export user data as CSV string"""
        try:
            entries = self.db.get_user_entries(user_id, days=365)  # Export all data
            
            if not entries:
                return None
            
            output = io.StringIO()
            writer = csv.writer(output)
            
            # Write headers
            writer.writerow(self.texts.CSV_HEADERS)
            
            # Write data rows
            for entry in entries:
                # Parse emotions
                emotions = self._parse_emotions(entry.emotions) if entry.emotions else []
                emotions_str = ', '.join(emotions)
                
                # Parse tags
                tags = []
                if entry.tags:
                    try:
                        tags = json.loads(entry.tags)
                    except json.JSONDecodeError:
                        tags = [entry.tags]
                tags_str = ', '.join(tags) if tags else ''
                
                # Format row
                row = [
                    entry.ts_local.strftime('%Y-%m-%d'),  # –î–∞—Ç–∞
                    entry.ts_local.strftime('%H:%M'),     # –í—Ä–µ–º—è
                    entry.valence or '',                   # –í–∞–ª–µ–Ω—Ç–Ω–æ—Å—Ç—å
                    entry.arousal or '',                   # –ê–∫—Ç–∏–≤–∞—Ü–∏—è  
                    emotions_str,                          # –≠–º–æ—Ü–∏–∏
                    entry.cause or '',                     # –ü—Ä–∏—á–∏–Ω–∞
                    entry.body or '',                      # –¢–µ–ª–µ—Å–Ω—ã–µ –æ—â—É—â–µ–Ω–∏—è
                    entry.note or '',                      # –ó–∞–º–µ—Ç–∫–∞
                    tags_str                               # –¢–µ–≥–∏
                ]
                
                writer.writerow(row)
            
            return output.getvalue()
            
        except Exception as e:
            logger.error(f"Failed to export CSV for user {user_id}: {e}")
            return None
    
    def get_emotion_timeline(self, user_id: int, days: int = 30) -> List[Dict]:
        """Get emotion timeline for visualization"""
        entries = self.db.get_user_entries(user_id, days)
        
        timeline = []
        for entry in entries:
            emotions = self._parse_emotions(entry.emotions) if entry.emotions else []
            
            timeline.append({
                'timestamp': entry.ts_local.isoformat(),
                'date': entry.ts_local.strftime('%Y-%m-%d'),
                'time': entry.ts_local.strftime('%H:%M'),
                'emotions': emotions,
                'valence': entry.valence,
                'arousal': entry.arousal,
                'cause': entry.cause,
                'note': entry.note
            })
        
        return timeline


def test_analyzer():
    """Test the analyzer with sample data"""
    from .db import Database, Entry
    import tempfile
    import os
    
    # Create test database
    with tempfile.NamedTemporaryFile(suffix='.db', delete=False) as f:
        test_db_path = f.name
    
    try:
        db = Database(f'sqlite:///{test_db_path}')
        analyzer = WeeklyAnalyzer(db)
        
        # Create test user
        user = db.create_user(12345, 67890)
        
        # Test emotion grouping
        test_emotions = ['—Ä–∞–¥–æ—Å—Ç—å', '—Ç—Ä–µ–≤–æ–≥–∞', '—Å–ø–æ–∫–æ–π—Å—Ç–≤–∏–µ', '—É—Å—Ç–∞–ª–æ—Å—Ç—å', '–≤–æ–∑–º—É—â–µ–Ω–∏–µ', '–∞–ø–∞—Ç–∏—è']
        
        print("Testing emotion grouping:")
        for emotion in test_emotions:
            group = analyzer._get_emotion_group(emotion)
            print(f"  {emotion} -> {group}")
        
        # Add test entries with different emotion groups
        test_entries = [
            {'emotions': '["—Ä–∞–¥–æ—Å—Ç—å"]', 'cause': '–∑–∞–∫–æ–Ω—á–∏–ª –ø—Ä–æ–µ–∫—Ç'},
            {'emotions': '["—Ç—Ä–µ–≤–æ–≥–∞"]', 'cause': '–º–Ω–æ–≥–æ —Ä–∞–±–æ—Ç—ã'},  
            {'emotions': '["—Å–ø–æ–∫–æ–π—Å—Ç–≤–∏–µ"]', 'cause': '–≤–µ—á–µ—Ä –¥–æ–º–∞'},
            {'emotions': '["—É—Å—Ç–∞–ª–æ—Å—Ç—å"]', 'cause': '–¥–æ–ª–≥–∏–π –¥–µ–Ω—å'},
            {'emotions': '["–≤–æ–∑–º—É—â–µ–Ω–∏–µ"]', 'cause': '–ø—Ä–æ–±–∫–∞ –Ω–∞ –¥–æ—Ä–æ–≥–µ'},
        ]
        
        for entry_data in test_entries:
            db.create_entry(12345, **entry_data)
        
        import asyncio
        summary = asyncio.run(analyzer.generate_summary(12345))
        print("\nFixed summary:")
        print(summary)
        
        print("\nFixed analyzer tests completed!")
        
    finally:
        os.unlink(test_db_path)


if __name__ == "__main__":
    test_analyzer()
